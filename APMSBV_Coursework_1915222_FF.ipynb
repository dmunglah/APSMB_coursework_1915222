{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1fe4cf-8441-4608-9318-fac08d32c8ee",
   "metadata": {},
   "source": [
    "# The following code is also available on the following github: https://github.com/dmunglah/APSMB_coursework_1915222 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebfc1bb-8d97-480a-991b-bef4160ff1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary packages \n",
    "import sbmltoodepy\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg, optimize, stats\n",
    "import scipy.interpolate as interp\n",
    "import os\n",
    "import sbmltoodepy\n",
    "import tkinter\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fae328-027a-4d68-b0ec-c0a07b061eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-06 17:34:36--  https://ftp.ncbi.nlm.nih.gov/geo/series/GSE92nnn/GSE92972/suppl/GSE92972_RAW.tar\n",
      "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 130.14.250.7, 130.14.250.11, 2607:f220:41e:250::13, ...\n",
      "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.7|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 207308800 (198M) [application/x-tar]\n",
      "Saving to: ‘GSE92972_RAW.tar’\n",
      "\n",
      "GSE92972_RAW.tar    100%[===================>] 197.71M  39.1MB/s    in 5.6s    \n",
      "\n",
      "2022-08-06 17:34:42 (35.4 MB/s) - ‘GSE92972_RAW.tar’ saved [207308800/207308800]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Getting the dataset required for the analysis - mouse tumour lung cancer data (Mus musculus)\n",
    "!wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE92nnn/GSE92972/suppl/GSE92972_RAW.tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83827413-9144-4364-a3cb-0954ac6502de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzipping the downloaded zipped file and extractiing the data.\n",
    "!cd university \n",
    "!tar -xvf GSE92972_RAW.tar\n",
    "!gunzip *.gz \n",
    "!mkdir dataset_samples_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3b00bf-2a68-4f7d-8158-b88fd521f50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of ERR015617_1.fastq\n",
      "Approx 5% complete for ERR015617_1.fastq\n",
      "Approx 10% complete for ERR015617_1.fastq\n",
      "Approx 15% complete for ERR015617_1.fastq\n",
      "Approx 20% complete for ERR015617_1.fastq\n",
      "Approx 25% complete for ERR015617_1.fastq\n",
      "Approx 30% complete for ERR015617_1.fastq\n",
      "Approx 35% complete for ERR015617_1.fastq\n",
      "Approx 40% complete for ERR015617_1.fastq\n",
      "Approx 45% complete for ERR015617_1.fastq\n",
      "Approx 50% complete for ERR015617_1.fastq\n",
      "Approx 55% complete for ERR015617_1.fastq\n",
      "Approx 60% complete for ERR015617_1.fastq\n",
      "Approx 65% complete for ERR015617_1.fastq\n",
      "Approx 70% complete for ERR015617_1.fastq\n",
      "Approx 75% complete for ERR015617_1.fastq\n",
      "Approx 80% complete for ERR015617_1.fastq\n",
      "Approx 85% complete for ERR015617_1.fastq\n",
      "Approx 90% complete for ERR015617_1.fastq\n",
      "Approx 95% complete for ERR015617_1.fastq\n",
      "Analysis complete for ERR015617_1.fastq\n",
      "Started analysis of ERR015617_2.fastq\n",
      "Approx 5% complete for ERR015617_2.fastq\n",
      "Approx 10% complete for ERR015617_2.fastq\n",
      "Approx 15% complete for ERR015617_2.fastq\n",
      "Approx 20% complete for ERR015617_2.fastq\n",
      "Approx 25% complete for ERR015617_2.fastq\n",
      "Approx 30% complete for ERR015617_2.fastq\n",
      "Approx 35% complete for ERR015617_2.fastq\n",
      "Approx 40% complete for ERR015617_2.fastq\n",
      "Approx 45% complete for ERR015617_2.fastq\n",
      "Approx 50% complete for ERR015617_2.fastq\n",
      "Approx 55% complete for ERR015617_2.fastq\n",
      "Approx 60% complete for ERR015617_2.fastq\n",
      "Approx 65% complete for ERR015617_2.fastq\n",
      "Approx 70% complete for ERR015617_2.fastq\n",
      "Approx 75% complete for ERR015617_2.fastq\n",
      "Approx 80% complete for ERR015617_2.fastq\n",
      "Approx 85% complete for ERR015617_2.fastq\n",
      "Approx 90% complete for ERR015617_2.fastq\n",
      "Approx 95% complete for ERR015617_2.fastq\n",
      "Analysis complete for ERR015617_2.fastq\n",
      "Started analysis of ERR015618_1.fastq\n",
      "Approx 5% complete for ERR015618_1.fastq\n",
      "Approx 10% complete for ERR015618_1.fastq\n",
      "Approx 15% complete for ERR015618_1.fastq\n",
      "Approx 20% complete for ERR015618_1.fastq\n",
      "Approx 25% complete for ERR015618_1.fastq\n",
      "Approx 30% complete for ERR015618_1.fastq\n",
      "Approx 35% complete for ERR015618_1.fastq\n",
      "Approx 40% complete for ERR015618_1.fastq\n",
      "Approx 45% complete for ERR015618_1.fastq\n",
      "Approx 50% complete for ERR015618_1.fastq\n",
      "Approx 55% complete for ERR015618_1.fastq\n",
      "Approx 60% complete for ERR015618_1.fastq\n",
      "Approx 65% complete for ERR015618_1.fastq\n",
      "Approx 70% complete for ERR015618_1.fastq\n",
      "Approx 75% complete for ERR015618_1.fastq\n",
      "Approx 80% complete for ERR015618_1.fastq\n",
      "Approx 85% complete for ERR015618_1.fastq\n",
      "Approx 90% complete for ERR015618_1.fastq\n",
      "Approx 95% complete for ERR015618_1.fastq\n",
      "Analysis complete for ERR015618_1.fastq\n",
      "Started analysis of ERR015618_2.fastq\n",
      "Approx 5% complete for ERR015618_2.fastq\n",
      "Approx 10% complete for ERR015618_2.fastq\n",
      "Approx 15% complete for ERR015618_2.fastq\n",
      "Approx 20% complete for ERR015618_2.fastq\n",
      "Approx 25% complete for ERR015618_2.fastq\n",
      "Approx 30% complete for ERR015618_2.fastq\n",
      "Approx 35% complete for ERR015618_2.fastq\n",
      "Approx 40% complete for ERR015618_2.fastq\n",
      "Approx 45% complete for ERR015618_2.fastq\n",
      "Approx 50% complete for ERR015618_2.fastq\n",
      "Approx 55% complete for ERR015618_2.fastq\n",
      "Approx 60% complete for ERR015618_2.fastq\n",
      "Approx 65% complete for ERR015618_2.fastq\n",
      "Approx 70% complete for ERR015618_2.fastq\n",
      "Approx 75% complete for ERR015618_2.fastq\n",
      "Approx 80% complete for ERR015618_2.fastq\n",
      "Approx 85% complete for ERR015618_2.fastq\n",
      "Approx 90% complete for ERR015618_2.fastq\n",
      "Approx 95% complete for ERR015618_2.fastq\n",
      "Analysis complete for ERR015618_2.fastq\n"
     ]
    }
   ],
   "source": [
    "!fastqc ./dataset_samples_3/*fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "371ae7b5-0b3d-47c1-9c98-91a0ffa9e5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrimmomaticPE: Started with arguments:\n",
      " -phred33 ./dataset_samples_3/ERR015617_1.fastq ERR015617_2.fastq ./dataset_samples_3/ERR015618_1.fastq ERR015618_2.fastq ILLUMINACLIP:contams_forward_rev.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36\n",
      "Multiple cores found: Using 4 threads\n",
      "Exception in thread \"main\" java.io.FileNotFoundException: ERR015617_2.fastq (No such file or directory)\n",
      "\tat java.base/java.io.FileInputStream.open0(Native Method)\n",
      "\tat java.base/java.io.FileInputStream.open(FileInputStream.java:219)\n",
      "\tat java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)\n",
      "\tat org.usadellab.trimmomatic.fastq.FastqParser.parse(FastqParser.java:135)\n",
      "\tat org.usadellab.trimmomatic.TrimmomaticPE.process(TrimmomaticPE.java:268)\n",
      "\tat org.usadellab.trimmomatic.TrimmomaticPE.run(TrimmomaticPE.java:555)\n",
      "\tat org.usadellab.trimmomatic.Trimmomatic.main(Trimmomatic.java:80)\n"
     ]
    }
   ],
   "source": [
    "# trimming with trimmomatic - has been run already\n",
    "!trimmomatic PE -phred33 ./dataset_samples_3/ERR015617_1.fastq ERR015617_2.fastq ./dataset_samples_3/ERR015618_1.fastq ERR015618_2.fastq  ILLUMINACLIP:contams\\_forward\\_rev.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c84d10-3e93-4cfe-aed7-fdf8f35e8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processsing the data using Bash to obtain contigs\n",
    "!prokka *.fastq --outdir /home/david/university/ --prefix *.fastq\n",
    "!find . -name /home/david/*.gbk | while read line; do out=$(echo $line | cut -d. -f1-2); python /home/david/tools/gene_to_locus_tool.py $line ${out}.gene_to_contig; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e5724-cea8-4907-9026-f9c1b8505c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gene_to_locus script\n",
    "from Bio import SeqIO\n",
    "\n",
    "import argparse\n",
    "arg_parser = argparse.ArgumentParser( description = \"Parse gbk file and output a gene to locus mapping file\" )\n",
    "arg_parser.add_argument( \"gbk_file\" )\n",
    "arg_parser.add_argument( \"out_file\" )\n",
    "arguments = arg_parser.parse_args()\n",
    "\n",
    "gbk_filename = arguments.gbk_file\n",
    "faa_filename = arguments.out_file\n",
    "\n",
    "output_handle = open(faa_filename, \"w\")\n",
    "for seq_record in SeqIO.parse(gbk_filename, \"genbank\") :\n",
    "    print (\"Dealing with GenBank record %s\" % seq_record.id)\n",
    "    for seq_feature in seq_record.features :\n",
    "        if seq_feature.type==\"CDS\":\n",
    "            assert len(seq_feature.qualifiers['translation'])==1\n",
    "            output_handle.write(\">%s Start: %s Stop: %s Strand: %s From %s\\n\" % (\n",
    "                   seq_feature.qualifiers['locus_tag'][0],\n",
    "                   seq_feature.location.start,\n",
    "                   seq_feature.location.end,\n",
    "                   seq_feature.strand,\n",
    "                   seq_record.name))\n",
    "\n",
    "output_handle.close()\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84ffb2-a11d-42ac-ab9c-229ca35582a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing the contigs\n",
    "!find contigs/*.fa | while read line; do file=$(echo $line | cut -d/ -f2 | cut -d. -f1); mkdir indexed_contigs/${file}; bowtie2-build -f $line indexed_contigs/${file}/${file}; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74591cab-0ac8-45fa-818f-affeb5e73ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the bam files needed for analysis\n",
    "!find contigs/*.fa | while read line; do file=$(echo $line | cut -d/ -f2 | cut -d. -f1); do bowtie2 -p 16 -x indexed_contigs/${file}/${file} -U /datadrive/david/fastq/${file}.fastq.gz | samtools sort > indexed_contigs/${file}/${file}.bam; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e2c241-1b8b-4402-89e2-40a74cdf2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Kraken and Braken to obtain abundance estimation\n",
    "!while read line; do identifier=$(echo $line | cut -d/ -f6 | cut -d. -f1); kraken2 --db . ${line} --report kraken_out_3/${identifier}.report --output kraken_out_3/${identifier}.out ; done < sequencing_files.txt\n",
    "!for i in `cat ids_kraken ` ; do bracken -d /datadrive/david/. -i $i.report -l S -o $i.output.bracken ; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc0e29-75e5-41a9-acae-6f043027aee1",
   "metadata": {},
   "source": [
    "# Used the following code to combine samples into an abundance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ee421-9c02-4530-84f0-9826a97892ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine sample files into table using this script\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import ntpath\n",
    "from functools import reduce\n",
    "\n",
    "\"\"\"\n",
    "Input -- \n",
    "1.)Directory or Folder containing bracken outputs\n",
    "2.)Metadata file with no headers, with first column as Bodysite/Status \n",
    "    and second column accession number/Sample ID\n",
    "  * Change the name of columns in the metadata_collist variable according to columns in metadata file \n",
    "  * More columns for metadata could be added,by specifying column names in the metadata_collist variable\n",
    "    \n",
    "3.) Directory containing kraken outputs\n",
    "\"\"\"\n",
    "\n",
    "#Function to extract accesion numbers from the bracken output filename\n",
    "def path_accession(path):\n",
    "    g = ntpath.basename(path)\n",
    "    ac = g.split('.')[0]\n",
    "    return ac\n",
    "\n",
    "def parse_kraken_report(listofkrakenoutputs):\n",
    "    listkraken = []\n",
    "    for kraken in listofkrakenoutputs:\n",
    "        f = ntpath.basename(kraken)\n",
    "        filename = f.split('.')\n",
    "        listkraken.append(pd.read_csv(kraken, sep='\\t', header=None, usecols = [1],nrows = 1).assign(name = filename[0]))\n",
    "    df = pd.concat(listkraken)\n",
    "    df = df.set_index('name')\n",
    "    df = df.rename(columns = {1:'Unclassified'})\n",
    "    return df\n",
    "        \n",
    "\n",
    "def main():\n",
    "  directory = sys.argv[1]\n",
    "  all_files = glob.glob(directory + \"/*.output.bracken\")\n",
    "  metadata_file = sys.argv[2]\n",
    "  directory_kraken = sys.argv[3]\n",
    "  kraken_files = glob.glob(directory_kraken + \"/*.report\")\n",
    "  kraken_df = parse_kraken_report(kraken_files)\n",
    "  output_file = 'Bracken_kraken.csv'\n",
    "  dataframe_list = bracken_to_df(all_files,col_list)\n",
    "  df_final = merged_df_listofdfs(dataframe_list)\n",
    "  df_t = df_final.T\n",
    "  try:\n",
    "   df_t = df_t.rename(columns=df_t.iloc[0])\n",
    "   df_t = df_t.drop('name',axis = 0)\n",
    "  except:\n",
    "   print('No files with .bracken extension in the current folder')\n",
    "  accesion_list = [path_accession(path) for path in all_files]\n",
    "  print(len(accesion_list))\n",
    "  print(df_t.shape)\n",
    "  df_t.index = accesion_list\n",
    "  #metadata = pd.DataFrame()\n",
    "  #try:\n",
    "  #metadata = pd.read_csv(metadata_file,header = None,names = metadata_collist,sep = '\\t', engine= 'c')\n",
    "  #metadata = metadata.set_index('sample_id')\n",
    "  #except:\n",
    "  #print('Metadata file does not have column names specified on metadata_collist variable')\n",
    "  final_list = [df_t,kraken_df]\n",
    "  tax_matrix = reduce(lambda left,right: pd.merge(left,right,left_index = True, right_index = True),final_list) \n",
    "  ##tax_matrix =  pd.merge(df_t,metadata,left_index = True,right_index= True)\n",
    "  print(tax_matrix)\n",
    "  tax_matrix.to_csv(output_file,sep = '\\t')\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17ca7e82-3ce3-4221-90a4-d43ef1cb64fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 2496)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the data and utilising an N-dimetional arrray to process the data. \n",
    "filedata_1 = pd.read_csv('/datadrive/david/Bracken_kraken11.tsv', sep='\\t')\n",
    "filedata_1.head\n",
    "filedata_2d = np.array(filedata_1)\n",
    "filedata_2d.shape\n",
    "#arr_2d = np.reshape(filedata, (3, 1))\n",
    "#arr_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0930c608-f85d-48fa-acc6-ecf5d4372db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-08 11:04:59--  https://www.ebi.ac.uk/biomodels/model/download/BIOMD0000000427.2?filename=BIOMD0000000427_url.xml\n",
      "Resolving www.ebi.ac.uk (www.ebi.ac.uk)... 193.62.193.80\n",
      "Connecting to www.ebi.ac.uk (www.ebi.ac.uk)|193.62.193.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/xml]\n",
      "Saving to: ‘BIOMD0000000427.2?filename=BIOMD0000000427_url.xml.1’\n",
      "\n",
      "BIOMD0000000427.2?f     [ <=>                ]  53.63K  --.-KB/s    in 0.09s   \n",
      "\n",
      "2022-08-08 11:04:59 (568 KB/s) - ‘BIOMD0000000427.2?filename=BIOMD0000000427_url.xml.1’ saved [54914]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# downloading a a suitable model\n",
    "!wget https://www.ebi.ac.uk/biomodels/model/download/BIOMD0000000427.2?filename=BIOMD0000000427_url.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "815cb5e8-7a9c-4895-b9e9-b9f0e2739fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sbmltoodepy in /home/david/miniconda3/envs/qiime2-2021.11/lib/python3.8/site-packages (1.0.4)\n",
      "Requirement already satisfied: numpy in /home/david/miniconda3/envs/qiime2-2021.11/lib/python3.8/site-packages (from sbmltoodepy) (1.21.2)\n",
      "Requirement already satisfied: python-libsbml in /home/david/miniconda3/envs/qiime2-2021.11/lib/python3.8/site-packages (from sbmltoodepy) (5.19.6)\n",
      "Requirement already satisfied: scipy in /home/david/miniconda3/envs/qiime2-2021.11/lib/python3.8/site-packages (from sbmltoodepy) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "#intalling sbmltoodepy\n",
    "!pip install sbmltoodepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fcea187-a790-4ef6-bad3-fc016a1f1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identified a model that contains a representation of a part of my system \n",
    "sbmltoodepy.ParseAndCreateModel(\"/home/david/university/BIOMD0000000427.2?filename=BIOMD0000000427_url.xml\", outputFilePath = \"Lockefile.py\", className = \"Lockemodel\")\n",
    "from Lockefile import Lockemodel\n",
    "model = Lockemodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027bb0e0-65b9-4f7d-8b10-415c39135a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['gamma_IGFR', 'kd_PI3K_a', 'k_P90Rsk_ERKActive', 'KM_P90Rsk_ERKActive', 'gamma_EGFR'])\n",
      "dict_keys(['EGFR_active', 'D_SOS', 'A_SOS', 'Raf', 'Ras_active', 'Mek_active', 'ERK', 'ERK_active', 'IGFR_active', 'PI3KCA', 'PI3KCA_active', 'AKT_active', 'AKT', 'PP2A', 'Ras', 'Raf_active', 'Mek', 'RasGapActive', 'RafPP', 'P90RskInactive', 'P90Rsk_Active'])\n",
      "dict_keys(['cell_nsclc'])\n"
     ]
    }
   ],
   "source": [
    "# Get the dictionary keys for the IDs of the parameters in the model\n",
    "print(model.p.keys())\n",
    "print(model.s.keys())\n",
    "print(model.c.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ead8f172-ea3d-4a1e-a41e-62dc691d36bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.005\n",
      "8000.0\n",
      "8000.0\n"
     ]
    }
   ],
   "source": [
    "# replace compartmentId with one of the dictionary keys returned from print(modelInstance.c.keys())\n",
    "print(model.c['cell_nsclc'].size) \n",
    "# replace parameterId with one of the dictionary keys returned from print(modelInstance.p.keys())\n",
    "print(model.p['kd_PI3K_a'].value)\n",
    "# replace speciesId with one of the dictionary keys returned from print(modelInstance.s.keys())\n",
    "print(model.s['EGFR_active'].concentration)\n",
    "print(model.s['EGFR_active'].amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a287df3d-ee9d-4589-b7f2-6cb29b90e1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(model.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57379877-694f-412a-83ea-bc83dc8e9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solving differential equation\n",
    "# function that returns dy/dt\n",
    "from scipy.integrate import odeint\n",
    "y = odeint(model, y0, t)\n",
    "\n",
    "def model(y,t):\n",
    "    dydt = -y + 1.0\n",
    "    return dydt\n",
    "\n",
    "# initial condition\n",
    "y0 = 0\n",
    "\n",
    "# time points\n",
    "t = np.linspace(0,0.005)\n",
    "\n",
    "# solve ODE\n",
    "y = odeint(model,y0,t)\n",
    "\n",
    "# plot results\n",
    "plt.plot(t,y)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('y(t)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f79c0da9-b4af-41b2-8be7-a432b98cc223",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeinterval = 1\n",
    "model.RunSimulation(timeinterval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ec9cbd7-4d0f-40f3-a7da-a0e74c6b77f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(model.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "432d92be-d455-48f5-977a-352eb935f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.zeros(101)\n",
    "times[0] = model.time\n",
    "concentrations = np.zeros(101)\n",
    "concentrations[0] = model.s['EGFR_active'].concentration\n",
    "timeinterval = 1\n",
    "for i in range(100):\n",
    "    model.RunSimulation(timeinterval)\n",
    "    times[i+1] = model.time\n",
    "    concentrations[i+1] = model.s['EGFR_active'].concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de31a2f1-255d-48a4-ac1c-4f0c7fe9251f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3a39d06700>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plotting \n",
    "import tkinter\n",
    "matplotlib.use('TkAgg')\n",
    "plt.plot(times,concentrations)\n",
    "#plt.show() #displays figure via X11 - will be on git hub page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ab99cbb-0dfd-4c53-9b03-a546b0900b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to plot network\n",
    "import networkx as nx\n",
    "\n",
    "adjacency_matrix = filedata_2d\n",
    "def squarify(adjacency_matrix,val):\n",
    "    (a,b)=adjacency_matrix.shape\n",
    "    if a>b:\n",
    "        padding=((0,0),(0,a-b))\n",
    "    else:\n",
    "        padding=((0,b-a),(0,0))\n",
    "    return numpy.pad(adjacency_matrix,padding,mode='constant',constant_values=val)\n",
    "#print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "faef841c-0448-459d-8fa4-c6b35e909b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G = nx.Graph(adjacency_matrix, nodetype=int)\n",
    "#G.edges()\n",
    "G = nx.Graph()\n",
    "G.add_edges_from('/home/david/abundance_tables/sample_list.txt)\n",
    "nx.draw_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e39d1-cf21-490f-8c59-06173df1b0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
